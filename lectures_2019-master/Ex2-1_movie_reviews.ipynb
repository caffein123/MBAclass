{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkred\">\n",
    "\n",
    "# Example 2-1: Classifying movie review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T03:51:45.030973Z",
     "start_time": "2019-03-07T03:51:42.286795Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras import optimizers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The IMDB dataset\n",
    "\n",
    "\n",
    "- A set of 50,000 highly-polarized reviews from the Internet Movie Database\n",
    "    - 25,000 reviews for training and 25,000 reviews for testing\n",
    "    - 50% negative(label=0) and 50% positive(label=1) reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T03:51:50.028129Z",
     "start_time": "2019-03-07T03:51:45.033100Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- `num_words=10000`: keep the top 10,000 most frequently occurring words in the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T03:51:50.035204Z",
     "start_time": "2019-03-07T03:51:50.030038Z"
    }
   },
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T03:51:50.047416Z",
     "start_time": "2019-03-07T03:51:50.036915Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 리뷰를 구성하는 단어 인덱스 리스트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T03:51:51.401103Z",
     "start_time": "2019-03-07T03:51:51.394624Z"
    }
   },
   "outputs": [],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 리뷰를 긍정=1 또는 부정=0 으로 나타내는 리스트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T03:51:51.772727Z",
     "start_time": "2019-03-07T03:51:51.766263Z"
    }
   },
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T03:51:52.539506Z",
     "start_time": "2019-03-07T03:51:52.369543Z"
    }
   },
   "outputs": [],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 가장 자주 등장하는 단어 10000개로 제한했기 때문에 단어 인덱스는 9999가 최대값 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T03:51:53.594983Z",
     "start_time": "2019-03-07T03:51:53.458955Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# word_index is a dictionary mapping words to an integer index\n",
    "word_index = imdb.get_word_index()\n",
    "# We reverse it, mapping integer indices to words\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `word_index`: 단어를 key로, 정수 인덱스를 value로 매칭하는 딕셔너리 \n",
    "- `reverse_word_index`: 정수 인덱스를 key로, 단어를 value로 매칭하는 딕셔너리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T03:51:54.623683Z",
     "start_time": "2019-03-07T03:51:54.617174Z"
    }
   },
   "outputs": [],
   "source": [
    "word_index['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T04:01:02.980050Z",
     "start_time": "2019-03-07T04:01:02.973811Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reverse_word_index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T06:20:02.406190Z",
     "start_time": "2019-02-18T06:20:02.400431Z"
    }
   },
   "outputs": [],
   "source": [
    "reverse_word_index.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T04:01:34.519684Z",
     "start_time": "2019-03-07T04:01:34.508232Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T04:08:46.858712Z",
     "start_time": "2019-03-07T04:08:46.853284Z"
    }
   },
   "outputs": [],
   "source": [
    "# We decode the review; note that our indices were offset by 3\n",
    "# because 0, 1 and 2 are reserved indices for \"padding\", \"start of sequence\", and \"unknown\".\n",
    "decoded_review = ' '.join([reverse_word_index.get(i-3 , '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0번째 리뷰를 문장으로 복원 \n",
    "- 0=\"padding\", 1=\"start of sequence\", 2=\"unknown\"을 위한 인덱스로 사용하고 있으므로 3을 빼서 단어로 복원 \n",
    "- 참고: https://keras.io/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T04:08:47.947087Z",
     "start_time": "2019-03-07T04:08:47.941104Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data\n",
    "- 한 문장을 $10000\\times 1$ vector로 변환\n",
    "    - 문장이 포함하고 있는 단어 자리는 1, 포함하지 않은 단어 자리는 0으로 채워진 벡터로 변환\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T06:57:05.964441Z",
     "start_time": "2019-02-18T06:57:05.957831Z"
    }
   },
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # Create an all-zero matrix of shape (len(sequences), dimension)\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T06:57:35.876319Z",
     "start_time": "2019-02-18T06:57:30.340592Z"
    }
   },
   "outputs": [],
   "source": [
    "# Our vectorized training data\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# Our vectorized test data\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T06:57:35.882664Z",
     "start_time": "2019-02-18T06:57:35.878320Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T06:57:35.910532Z",
     "start_time": "2019-02-18T06:57:35.884277Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T06:58:36.902624Z",
     "start_time": "2019-02-18T06:58:36.897850Z"
    }
   },
   "outputs": [],
   "source": [
    "# Our vectorized labels\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T06:58:41.964830Z",
     "start_time": "2019-02-18T06:58:41.958516Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T11:42:11.512434Z",
     "start_time": "2018-07-12T11:42:11.503743Z"
    }
   },
   "outputs": [],
   "source": [
    "np.shape(x_train), np.shape(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building our network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![3-layer network](https://s3.amazonaws.com/book.keras.io/img/ch3/3_layer_network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T07:22:18.342307Z",
     "start_time": "2019-02-18T07:22:18.285374Z"
    }
   },
   "outputs": [],
   "source": [
    "K.clear_session() \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input은 10000개 단어에 대한 one-hot vector로 표현된 단어들 \n",
    "- 16개 hidden unit이 있는 layer 2개로 구성 \n",
    "- 각 layer에서 activation funtion $\\sigma(\\cdot)$을 ReLU 함수를 사용 \n",
    "\n",
    "<img src=\"figures/relu.PNG\" width=350>\n",
    "- Output은 긍정의 확률을 나타내는 하나의 숫자. Sigmoid 함수 사용 \n",
    "<img src=\"figures/sigmoid.PNG\" width=350>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T07:32:29.952846Z",
     "start_time": "2019-02-18T07:32:29.902554Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.adam(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Loss function:`binary_crossentropy` for binary classification \n",
    "- Optimizer:  `rmsprop` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating our approach\n",
    "\n",
    "Create a \"validation set\" by setting apart 10,000 samples from the original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T07:32:36.192793Z",
     "start_time": "2019-02-18T07:32:36.186150Z"
    }
   },
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T07:34:27.326837Z",
     "start_time": "2019-02-18T07:33:52.009236Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `batch_size=512`: 512개의 샘플씩 미니 배치를 만들어 gradient를 업데이트 \n",
    "- `epochs=20`: 모든 샘플에 대해 20번 반복 \n",
    "- `validation_data=(x_val, y_val)`: 주어진 validation set에 대해 검증 데이터 전달 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T07:53:30.674893Z",
     "start_time": "2019-02-18T07:53:30.667936Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `model.fit`은 history 객체를 반환. 훈련동안의 모든 정보를 담고 있는 딕셔너리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T07:43:53.143426Z",
     "start_time": "2019-02-18T07:43:52.892704Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습이 진행되면서 training loss는 점차 감소 \n",
    "- 학습이 진행되면서 validation loss는 감소하다가 4번째 epoch 이후 증가\n",
    "    - training data에 대해서는 잘 작동하지만 처음 보는 데이터에는 잘 작동하지 않음: overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T07:53:33.478766Z",
     "start_time": "2019-02-18T07:53:33.270125Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a trained network to generate predictions on new data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Overfitting이 발생하기 직전까지 4번의 epoch만 적합시킨 모형으로 test set을 예측하는데 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T08:00:17.138173Z",
     "start_time": "2019-02-18T08:00:07.348793Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.adam(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T08:00:28.632582Z",
     "start_time": "2019-02-18T08:00:28.627839Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T14:16:13.396340Z",
     "start_time": "2019-02-18T14:16:12.064283Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `x_test`에 대해 모형을 통해 예측한 값을 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T14:16:50.141824Z",
     "start_time": "2019-02-18T14:16:50.136979Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkgreen\">\n",
    "\n",
    "__NOTE__\n",
    "- 위의 예제에서는 20번의 epoch를 먼저 학습시켜 overfitting 여부를 체크한 후 다시 한번 모형을 적절한 epoch 만큼 학습시키는 과정을 진행했음\n",
    "- 하지만 학습시간이 오래걸리는 문제에서는 이 방식이 비효율적임\n",
    "- tensorboard를 활용한다면 학습하면서 동시에 overfitting을 체크하며 model tuning 과정을 보다 효율적으로 진행할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "References\n",
    "- [Deep Learning with Python, François Chollet,](https://www.manning.com/books/deep-learning-with-python)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
