{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3-1: Predicting house prices\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Boston Housing Price dataset\n",
    "\n",
    "\n",
    "- Predict the median price of homes in a given Boston suburb in the mid-1970s\n",
    "- 404 training samples and 102 test samples, and each \"feature\" in the input data \n",
    "- Each feature has has a different scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) =  boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 13 features of the input data\n",
    "\n",
    "    1. Per capita crime rate.\n",
    "    2. Proportion of residential land zoned for lots over 25,000 square feet.\n",
    "    3. Proportion of non-retail business acres per town.\n",
    "    4. Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "    5. Nitric oxides concentration (parts per 10 million).\n",
    "    6. Average number of rooms per dwelling.\n",
    "    7. Proportion of owner-occupied units built prior to 1940.\n",
    "    8. Weighted distances to five Boston employment centres.\n",
    "    9. Index of accessibility to radial highways.\n",
    "    10. Full-value property-tax rate per $10,000.\n",
    "    11. Pupil-teacher ratio by town.\n",
    "    12. 1000 * (Bk - 0.63) ** 2 where Bk is the proportion of Black people by town.\n",
    "    13. % lower status of the population.\n",
    "\n",
    "\n",
    "- target: the median values of owner-occupied homes, in thousands of dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "- Feaure-wise normalization \n",
    "    - 각 feature 별로 평균을 빼고 표준편차로 나눠줌으로써 평균 0, 표준편차 1이 되도록 만듬\n",
    "    - train set의 평균과 표준편차 만을 활용하여 test와 train  set 모두 표준화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our network\n",
    "<font color=blue>\n",
    "TO DO: \n",
    " \n",
    "- layer 두 개를 사용하는 모델을 생성하고 compile하는 `build_model` 이름의 함수를 만드시오.\n",
    "- `build_model` 함수의 input: node의 수, optimizer 종류\n",
    "- `build_model` 함수의 output: compile된 model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def build_model(   # Your inputs here #            ):\n",
    "    # your models here #\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return # your output here #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = train_data[:80]\n",
    "partial_train_data = train_data[80:]\n",
    "val_targets = train_targets[:80]\n",
    "partial_train_targets = train_targets[80:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare batch sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "    \n",
    "TO DO: `adam` opimizer를 사용하고 node수를 64로 고정한 후 batch size를 1-50 사이의 값에서 변화시키며 learning curve(training and validation loss)의 변화를 관찰하시오. \n",
    "- `partial_train_data`와 `partial_train_targets`를 train set으로 사용\n",
    "- `val_data`와 `val_targets`를 validation set으로 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code comes here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "TO DO: validation loss 관점에서 최적의 모형을 결정하고 전체 `train_data`와 `train_targets`를 사용하여 모형을 학습시킨 뒤 test set에 대한 loss와 mae 값을 출력하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code comes here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold CV using Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=build_model, epochs=100, batch_size=50, verbose=0)  \n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=7) \n",
    "results = cross_val_score(model, train_data, train_targets, cv=kfold, scoring='neg_mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Results: %.2f (%.2f)\" % (results.mean(), results.std()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (NGC/TensorFlow 18.12) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
