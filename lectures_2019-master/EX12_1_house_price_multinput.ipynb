{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex 12-1. House price prediction: Multi-input model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 집 가격에 영향을 미치는 것은 무엇이 있을까?\n",
    "    - 지역\n",
    "    - 크기\n",
    "    - 방의 개수\n",
    "    - 집이 얼마나 멋진가! \n",
    "- 집 가격을 예측하기 위해 정형데이터와 이미지 데이터를 함께 사용해보도록 하자.\n",
    "![](https://www.pyimagesearch.com/wp-content/uploads/2019/01/keras_regression_cnns_houses.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import Dense, Activation, Dropout, Dense, Conv2D, MaxPooling2D, Flatten, Input, concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "### Structured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath = \"data/Houses Dataset/HousesInfo.txt\"\n",
    "cols = [\"bedrooms\", \"bathrooms\", \"area\", \"zipcode\", \"price\"]\n",
    "df = pd.read_csv(inputPath, sep=\" \", header=None, names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"zipcode\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 지역(zipcode)가 몇 군데에 몰려 있음.\n",
    "- 관측치가 25개보다 적은 지역은 빼고 분석을 진행하기로 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df[\"zipcode\"].value_counts()\n",
    "zipcodes = counts[counts>25].keys()\n",
    "df = df.loc[df.zipcode.isin(zipcodes)]\n",
    "df.zipcode.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- zipcode를 one-hot encoding으로 변환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.zipcode = df.zipcode.astype('category')\n",
    "df = pd.concat([df, pd.get_dummies(df.zipcode)], axis=1)\n",
    "df = df.drop(\"zipcode\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- price를 제외한 나머지를 X로, price를 Y로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"price\", axis=1)\n",
    "Y = df[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 한 집에 대해 네 장의 사진이 아래와 같은 이름으로 저장되어 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image.load_img(\"data/Houses Dataset/1_frontal.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.load_img(\"data/Houses Dataset/1_bedroom.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.load_img(\"data/Houses Dataset/1_kitchen.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.load_img(\"data/Houses Dataset/1_bathroom.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미지를 순차적으로 불러와서 (64, 64) 픽셀로 변환\n",
    "- images_bathroom, images_bedroom, images_frontal, images_kitchen의 이름으로 각 종류의 이미지를 np.array로 모아서 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"data/Houses Dataset\"\n",
    "\n",
    "img_names = [\"bathroom\", \"bedroom\", \"frontal\", \"kitchen\"]\n",
    "for i, name in enumerate(img_names):\n",
    "    exec(\"images_%s = []\" % name)\n",
    "    \n",
    "for i in df.index.values:\n",
    "    basePath = os.path.sep.join([input_path, \"{}_*\".format(i + 1)])\n",
    "    housePaths = sorted(list(glob.glob(basePath)))\n",
    "    inputImages = []\n",
    "    for housePath in housePaths:\n",
    "        img = image.load_img(housePath, target_size=(64, 64))\n",
    "        x = image.img_to_array(img)\n",
    "        x = x/225.\n",
    "        inputImages.append(x)\n",
    "    \n",
    "    for j, name in enumerate(img_names):\n",
    "        exec(\"images_%s.append(inputImages[%d])\" % (name, j))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train, test set으로 나누고 np.array로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "split = train_test_split(X, Y, images_bathroom, images_bedroom, images_frontal, images_kitchen, \n",
    "                         test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names = [\"X\", \"Y\", \"bathroom\", \"bedroom\", \"frontal\", \"kitchen\"]\n",
    "for i, name in enumerate(var_names):\n",
    "    exec(\"train_%s = np.array(split[%d])\" % (name, 2*i))\n",
    "    exec(\"test_%s = np.array(split[%d])\" % (name, 2*i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_X.shape, train_Y.shape, train_bathroom.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X에 대해 train set을 기준으로 min-max transformation 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "test_X = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Y는 최대 가격을 기준으로 0-1 사이의 값으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maxprice = train_Y.max()\n",
    "train_Y /= maxprice\n",
    "test_Y /= maxprice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 16개의 node를 가진 두 개의 dense layer를 포함하는 모형을 만들고자 한다. (16,16)을 입력으로 받아 for loop와 keras functional API를 사용하여 자동화 하는 코드를 작성해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(5,))\n",
    "nodes = (16, 16)\n",
    "for (i, f) in enumerate(nodes):\n",
    "    if i==0:\n",
    "        x = inputs\n",
    "    x = Dense(f, activation=\"relu\")(x)\n",
    "model = Model(inputs, x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "\n",
    "TO DO: 아래의 사항을 반영하여 DNN 모형을 만드는 함수를 완성하시오. \n",
    "- input layer의 shape을 `dim`으로 입력받음.\n",
    "- 각 dense layer의 node의 개수를 tuple형식으로 `nodes`로 입력받음.\n",
    "- 각 layer의 activation은 \"relu\"로 고정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(dim, nodes=(8,4)):\n",
    "    # Your answer comes here\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = create_mlp(10, (16, 8, 4))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "\n",
    "TO DO: 아래의 사항을 반영하여 CNN 모형을 만드는 함수를 완성하시오. \n",
    "- input layer의 shape을 `inputshape`으로 tuple 형태를 입력받음.\n",
    "- 각 Convolution layer의 filter의 수를 `filters`로 tuple 형태를 입력받음.\n",
    "- 각 `Conv2D` layer 뒤에 (2,2)를 사용한 maxpooling layer를 연결함.\n",
    "- `filters`에 입력된 만큼의 Conv-Maxpooling layer를 쌓은 뒤 아래의 layer를 연결함.\n",
    "    - Flatten\n",
    "    - Dense(16)\n",
    "    - Dropout(0.5)\n",
    "    - Dense(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(inputshape, filters=(16, 32)):\n",
    "    # Your answer comes here\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_cnn((32,32,3), filters=(8, 16, 32))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) DNN model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "    \n",
    "TO DO: 위에서 작성한 `create_mlp` 함수를 사용하여 `train_X`를 input으로, `train_Y`를 output으로 하는 DNN 모형을 만드시오.  8, 4의 hidden nodes를 가지는 hidden layer를 포함하도록 만드시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer comes here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "    \n",
    "TO DO: 위에서 만든 모형을 훈련하시오. \n",
    "- `train_X, train_Y`을 train set으로 사용 \n",
    "- `test_X, test_Y`를 validation set으로 사용\n",
    "- epoch=100\n",
    "- batch size=8\n",
    "- adam optimizer 사용\n",
    "- 훈련 시  mae(mean absolute error)를 함께 모니터\n",
    "- 훈련 과정의 loss를 확인하기 위해 model.fit을 `history`이름으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your answer comes here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min(history.history['val_mean_absolute_error'])*maxprice, min(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, 101)\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, train_loss, 'b+', label='train_loss')\n",
    "plt.plot(epochs, val_loss, 'bo', label='val_loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) CNN model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "    \n",
    "TO DO: \n",
    "- 위에서 작성한 `create_cnn` 함수를 사용하여 bathroom, bedroom, frontal, test_kitchen의 각 사진들을 input으로 받는 4 개의 개별적인 CNN 모형을 만드시오.  \n",
    "- 위에서 만들어진 4개의 모형의 output을 `concatenate` layer로 묶으시오. \n",
    "- 4개의 node를 가진 dense layer를 추가하고 output layer를 추가하여 가격을 예측하는 모형을 만드시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model1 = \n",
    "cnn_model2 = \n",
    "cnn_model3 = \n",
    "cnn_model4 = \n",
    "\n",
    "# Your answer comes here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "    \n",
    "TO DO: 위에서 만든 모형을 훈련하시오. \n",
    "- 4개의 집 공간에 대한 train 이미지들을 입력으로 사용\n",
    "- test 이미지와 Y를 validation set으로 사용 \n",
    "- epoch=100\n",
    "- batch size=8\n",
    "- adam optimizer 사용\n",
    "- 훈련 시  mae(mean absolute error)를 함께 모니터\n",
    "- 훈련 과정의 loss를 확인하기 위해 model.fit을 `history`이름으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer comes here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(history.history['val_mean_absolute_error'])*maxprice, min(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, 101)\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, train_loss, 'b+', label='train_loss')\n",
    "plt.plot(epochs, val_loss, 'bo', label='val_loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) DNN + CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "    \n",
    "TO DO: \n",
    "- (1)의 DNN 모형,  (2)의 네 개의 CNN 모형을 동일하게 만드시오 \n",
    "- 위에서 만들어진 5개의 모형의 output을 `concatenate` layer로 묶으시오. \n",
    "- 4개의 node를 가진 dense layer를 추가하고 output layer를 추가하여 가격을 예측하는 모형을 만드시오. \n",
    "- (1), (2)와 같이 모형을 훈련하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your answer comes here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(history.history['val_mean_absolute_error'])*maxprice, min(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, 101)\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, train_loss, 'b+', label='train_loss')\n",
    "plt.plot(epochs, val_loss, 'bo', label='val_loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (NGC/TensorFlow 18.12) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
