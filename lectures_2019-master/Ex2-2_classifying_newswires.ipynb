{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkred\">\n",
    "\n",
    "# Example 2-1: Classifying newswires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Reuters dataset\n",
    "\n",
    "- 1986년에 로이터에서 공개한 짧은 뉴스 기사와 토픽의 집합\n",
    "- 46개의 토픽으로 분류하는 문제 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T11:35:24.071766Z",
     "start_time": "2019-02-18T11:35:21.505322Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "TO DO: 총 몇 개의 샘플이 train data와 test data에 포함되어 있는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer comes here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- IMDB movie review data처럼 각 샘플은 단어를 나타내는 인덱스로 이루어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "TO DO: 첫 번째 (index=0) 샘플의 기사를 단어로 디코딩 하고 해당 기사의 topic 레이블을 프린트 하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T11:43:55.089671Z",
     "start_time": "2019-02-18T11:43:55.080843Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your answer comes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "TO DO: `train_data`와 `test_data`의 샘플들을 각 단어를 나타내는 one-hot vector의 시퀀스로 변환하여 neural network의 입력 데이터의 형태로 만들고  `x_train`과 `x_test`의 이름으로 저장하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T13:13:48.026366Z",
     "start_time": "2019-02-18T13:13:46.886234Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your answer comes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "TO DO: `train_labels`와 `test_labels`를 46개의 범주를 구분하는 one-hot encoding으로 변환하시오. (참고: Lecture 1의 MNIST data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer comes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our network\n",
    "\n",
    "- Output의 dimension이 46개이기 때문에 IMDB 데이터의 2개보다 훨씬 큼\n",
    "- IMDB 모형보다는 더 많은 node를 가진 layer를 사용하는 것이 나음 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "TO DO: 아래의 설명에 따라 모형을 만드시오.\n",
    "\n",
    "- 64개의 node를 가지는 dense layer를 2개 사용. 각 layer는 ReLU activation 적용\n",
    "- Output layer는 softmax activation 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T14:11:33.698017Z",
     "start_time": "2019-02-18T14:11:33.628344Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your answer comes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "TO DO: `rmsprop` optimizer와 적절한 loss 함수를 사용하여  model을 compile 하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T14:11:34.238780Z",
     "start_time": "2019-02-18T14:11:34.204399Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your answer comes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating our approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T14:11:34.831342Z",
     "start_time": "2019-02-18T14:11:34.824113Z"
    }
   },
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "TO DO: `partial_x_train`, `partial_y_train`을 train data로, `x_val`, `y_val`을 validation data로 사용하여 모델을 학습하고 최적의 epoch 수를 찾으시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T14:11:45.966602Z",
     "start_time": "2019-02-18T14:11:35.731519Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your answer comes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display its loss and accuracy curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "TO DO: 최적의 epoch 수만큼 model을 다시 학습시키고 test set에 대해 model의 loss와 accuracy를 계산하시오.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer comes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "TO DO: `x_test`의 첫 번째 기사는 모형에 의해 몇 번째 topic으로 분류되었는가? 실제로는 몇 번째 topic에 해당하는 기사인가? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer comes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>\n",
    "TO DO: 다음의 변화를 시도하며 모형 성능이 어떻게 변하는지 관찰하고 test accuracy를 가장 크게 만드는 모형을 report 하시오. \n",
    "- 각 층의 node의 개수를 크게 혹은 작게 변화(32, 128 등) \n",
    "- Hidden layer의 수를 조정 (1개, 3개 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer comes here\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
