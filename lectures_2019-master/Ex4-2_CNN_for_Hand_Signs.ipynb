{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from keras import optimizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review: workflow\n",
    "\n",
    "#### (1) 문제 정의와 데이터셋 수집 \n",
    "- 무엇을 예측하려 하는가? 이를 예측하기 위한 training data가 있는가? \n",
    "- 예측하려는 문제의 종류는 무엇인가?\n",
    "    - Binary classification\n",
    "    - Multi-class classification \n",
    "    - Regression\n",
    "- Examples\n",
    "    - __숫자 손글씨의 인식 (0-9)__\n",
    "    - 영화 리뷰의 감성 분류 (positive/negative)\n",
    "    - 얼굴 사진의 감정 인식 (happy/unhappy)\n",
    "    \n",
    "\n",
    "#### (2) 성공 지표의 선택\n",
    "- 최종 모형 비교를 위한 지표 선택 \n",
    "- Binary classification: accuracy, ROC AUC, precision(=TP/(TP+FP)), recall(=TP/(TP+FN)), F1-measure 등\n",
    "- Multi-class classification: average precision 등\n",
    "- Regression: MSE, MAE\n",
    "- Keras에서 학습 과정의 validation set에 대한 metric으로서 AUC, precision, recall 등을 제공하지 않음(왜? mini-batch에 대한 위의 지표는 오히려 방해가 될 수 있음): Test set에서 계산하는 것이 바람직\n",
    "\n",
    "\n",
    "\n",
    "#### (3) 평가 방법 선택\n",
    "- Hold-out validation set 사용\n",
    "    - Train data의 일정 부분을 validation set으로 사용 \n",
    "    - 데이터의 양이 많을 때 사용하는 방법\n",
    "    - `keras.model.fit`의 `validation_data` 또는 `validation_split` option\n",
    "- K-fold cross-validation\n",
    "    - Train set을 K-개의 무작위 set으로 구분한 뒤 하나씩 validation set으로 사용하며 반복\n",
    "    - Hold-out validation set을 구성하기에 데이터가 적을 때 사용  \n",
    "    - Keras 자체의 cv 모듈이 없으므로 scikit-learn의 `KFold`를 사용 (참고: https://3months.tistory.com/321)\n",
    "\n",
    "\n",
    "#### (4) 데이터 준비 \n",
    "- Input data는 일반적으로 [-1,1] 혹은 [0,1] 사이의 데이터로 스케일 조정\n",
    "- 사용하려는 모델에 맞는 input 형태로 조정\n",
    "- 필요시 output data 형태 변환(ex. one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) Baseline보다 나은 모델 훈련 \n",
    "- 이진분류 라면 정확도 0.5, MNIST 데이터라면 정확도 0.1보다 높은 모형 만들기 \n",
    "- 적절한 layer 종류의 선택\n",
    "    - Dense\n",
    "    - Convolution\n",
    "    - Dropout\n",
    "    - Pooling\n",
    "    - Recurrent\n",
    "    - Embedding\n",
    "- 마지막 layer의 activation function 선택\n",
    "    - output의 형태에 따라 조정\n",
    "    - Sigmoid, softmax, linear 등\n",
    "- Loss function 선택\n",
    "    - 풀고자 하는 문제의 종류에 따라 선택\n",
    "    - binary_crossentropy, categorical_crossentropy, mse 등\n",
    "    - 미분 가능해야 하고 주어진 mini-batch에서 계산 가능해야 함. (ROC AUC 등은 사용 불가) \n",
    "- Optimizer와 learning rate 선택 \n",
    "    - rmsprop, adam과 default learning rate 사용이 무난 \n",
    "    \n",
    "<img src=\"figures/cheatsheet_loss.PNG\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=512, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred=model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (6) Scaling up: overfitting 모델 구축 \n",
    "- 충분한 성능을 나타내는 모델을 만들기 위해 모형을 크게 확장 \n",
    "    - Layer 추가 \n",
    "    - 각 layer의 unit 추가 \n",
    "    - Epoch 수 증가 \n",
    "- train loss와 validation loss를 모니터 \n",
    "\n",
    "#### (7) Regularization, hyperparameter tuning \n",
    "- 반복적으로 모델 수정, 훈련, 평가하며 모델 튜닝 \n",
    "    - Dropout 추가 \n",
    "    - Layer 추가 혹은 제거 \n",
    "    - L1 또는 L2 penalty 추가 \n",
    "    - Layer의 unit 수나 learning rate의 튜닝 \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=optimizers.adam(lr=0.01),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "import time \n",
    "now = time.strftime(\"%c\")\n",
    "callbacks_list = [\n",
    "    TensorBoard(log_dir='./logs/mnist/'+now),\n",
    "    ModelCheckpoint(filepath='./models/mnist.h5',monitor='val_loss',save_best_only=True)\n",
    "]\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=100, batch_size=512, validation_split=0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "#  Example 4-2. CNN for Hand Signs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손가락으로 숫자를 표현하는 사진들을 학습하여 나타내고 있는 숫자(0-6)를 예측하는 문제를 실습\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"figures/SIGNS.png\" style=\"width:800px;height:300px;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-19T14:51:35.297329Z",
     "start_time": "2019-02-19T14:51:32.170637Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install h5py\n",
    "#!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T06:30:24.963786Z",
     "start_time": "2019-02-12T06:30:22.972350Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras import optimizers\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T06:30:30.980915Z",
     "start_time": "2019-02-12T06:30:30.936294Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = h5py.File('data/train_signs.h5', \"r\")\n",
    "\n",
    "X_train_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "Y_train_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "test_dataset = h5py.File('data/test_signs.h5', \"r\")\n",
    "X_test_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "Y_test_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T06:30:31.529801Z",
     "start_time": "2019-02-12T06:30:31.519366Z"
    }
   },
   "outputs": [],
   "source": [
    "list(train_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T06:30:31.717661Z",
     "start_time": "2019-02-12T06:30:31.710385Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset[\"train_set_x\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T06:30:31.901480Z",
     "start_time": "2019-02-12T06:30:31.894274Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_orig.shape, Y_train_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_orig.shape, Y_test_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T06:30:32.717188Z",
     "start_time": "2019-02-12T06:30:32.478903Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example of a picture\n",
    "index = 0\n",
    "plt.imshow(X_train_orig[index])\n",
    "print (\"y = \" + str(Y_train_orig[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> \n",
    "TO DO: 데이터를 모델에 입력하기 적절한 형태로 변환하시오. model fitting 시 validation set과 training set으로 활용하기 위해 train data의 앞에서부터 200개를 `X_val, Y_val`으로 저장하고 나머지 train data를  `partial_X_train, partial_Y_train`으로 저장하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T06:30:33.068788Z",
     "start_time": "2019-02-12T06:30:32.966598Z"
    }
   },
   "outputs": [],
   "source": [
    "## Your answer comes here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model 구축\n",
    "<font color=\"blue\">\n",
    "TO DO: 상대적으로 간단한 layer, activation, loss, optimizer를 사용하여 모형을 구축하고 test accuracy를 통해 성능 확인하시오. Accuracy 1/6 이상의 적절한 성능이 나오는지 확인하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T06:30:33.476860Z",
     "start_time": "2019-02-12T06:30:33.383295Z"
    }
   },
   "outputs": [],
   "source": [
    "## Your answer comes here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning을 통한 모형 수정 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">\n",
    "\n",
    "TO DO: \n",
    "- layer 수의 결정\n",
    "- filter/node의 수와 learning rate을 인수로 하는 `build_model` 함수를 생성 \n",
    "- `build_model` 함수를 사용하여 몇 가지 모형 구조에서 learning rate을 random search를 통해 tuning 시도\n",
    "- test accuracy 기준으로 final model 선택 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your answer comes here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나의 사진 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">\n",
    "\n",
    "TO DO: \n",
    "    본인의 손가락으로 숫자를 표현하는 사진을 찍어 jpg형태로 저장한 후 figures folder에 업로드하고 아래의 코드를 실행하여 사진을 모형에 입력가능한 형태로 변환하시오. 변환된 사진을 학습된 모형에 입력하여 분류 결과를 확인하시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image \n",
    "\n",
    "img_path = 'figures/myhand.jpg'\n",
    "img = image.load_img(img_path, target_size=(64, 64))\n",
    "plt.imshow(img)\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = x/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "- https://www.coursera.org/specializations/deep-learning"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "bwbJV",
   "launcher_item_id": "0TkXB"
  },
  "kernelspec": {
   "display_name": "Python 3.5 (NGC/TensorFlow 18.12) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
